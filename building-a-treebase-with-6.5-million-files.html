<!--

 This page was compiled by ðŸ“œ Scroll, the public domain
 static site publishing software.
 
 http://scroll.publicdomaincompany.com/
 
 Generally you don't want to edit it by hand.

 Scroll v6.1.0

-->
<head>
 <meta charset="utf-8"></meta>
 <title>Breck Yunits' Scroll</title>
 <style>html {
  background-color: rgb(244,244,244);
  font-family: Exchange,Georgia,serif;
  color: #000;
  font-size: 10pt;
}
html,body,div,span,h1,h2,h3,h4,h5,h6,p {
  margin: 0;
  padding: 0;
  border: 0;
  vertical-align: baseline;
}
.scrollChrome {
  text-align: center;
  font-family: Retina,Arial,Helvetica,sans-serif;
  color: #333;
}
.scrollDescription {
  padding: 3px;
}
.scrollTitle a {
  font-family: Exchange,Georgia,serif;
  text-decoration: none;
  color: #000;
}
.scrollIcons {
  padding-top: 3px;
}
.scrollIcons svg {
  width: 30px;
  fill: rgba(204,204,204, .5);
  margin-left: 15px;
}
.scrollIcons svg:hover {
  fill: #333;
}
.scrollTopRightBar {
  text-align: right;
  position: absolute;
  right: 25px;
  top: 3px;
}
.scrollPage {
  column-count: auto;
  column-width: 35ch;
  column-gap: 20px;
  column-rule: 1px solid rgb(204,204,204);
  padding-left: 20px;
  padding-right: 20px;
  border-top: 1px solid rgb(204,204,204);
  border-bottom: 1px solid rgb(204,204,204);
  margin-top: 8px;
  margin-bottom: 8px;
}
.scrollArticleDate {
  text-align: center;
  font-style: italic;
  font-size: 80%;
  display: inline;
}
.scrollArticleSourceLink {
  text-align: center;
  font-size: 80%;
  margin: 0;
}
.scrollArticleSourceLink a {
  color: #000;
  text-decoration: none;
}
.scrollSingleArticle {
  padding-top: 10px;
  padding-bottom: 10px;
  column-rule: none;
}
.scrollSingleArticle .scrollArticleCell {
  break-inside: avoid-page;
  border-bottom: none;
}
.scrollArticleCell {
  border-bottom: 1px solid rgb(204,204,204);
  width: 35ch;
  padding: 1ch;
  break-inside: avoid;
  overflow: hidden;
  text-align: justify;
  margin: auto;
}
.scrollArticleCell ul,.scrollArticleCell ol {
  padding: 1em;
  margin: 0;
}
.scrollArticleCell p {
  text-indent: 1em;
}
.scrollArticleCell p:first-of-type {
  display: inline;
}
.scrollArticleCell img {
  max-width: 35ch;
}
.scrollArticleCell .scrollArticleCode,.scrollArticleCell table {
  margin-top: 15px;
  margin-bottom: 15px;
  background-color: rgb(234,234,234);
  padding: 1em;
  overflow: auto;
  font-size: 80%;
  break-inside: avoid;
}
.scrollArticleCell .scrollArticleCode,.scrollArticleCell table code {
  margin: 0;
  display: block;
  white-space: pre;
  break-inside: avoid;
}
.scrollArticleCell h1 a {
  text-decoration: none;
  color: #000;
}
.scrollArticleCell h1,.scrollArticleCell h2,.scrollArticleCell h3,.scrollArticleCell h4,.scrollArticleCell h5,.scrollArticleCell h6 {
  text-align: center;
}
.scrollArticleCell h2,.scrollArticleCell h3,.scrollArticleCell h4,.scrollArticleCell h5,.scrollArticleCell h6 {
  margin: .2em;
}
blockquote {
  margin: 2ch;
}
</style>
</head>
<body>
 <div class="scrollTopRightBar">
  <div class="scrollChrome scrollIcons">
   <a href="mailto:breck7@gmail.com"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Gmail icon</title><path d="M24 5.457v13.909c0 .904-.732 1.636-1.636 1.636h-3.819V11.73L12 16.64l-6.545-4.91v9.273H1.636A1.636 1.636 0 0 1 0 19.366V5.457c0-2.023 2.309-3.178 3.927-1.964L5.455 4.64 12 9.548l6.545-4.91 1.528-1.145C21.69 2.28 24 3.434 24 5.457z"/></svg></a>
   <a href="https://twitter.com/breckyunits"><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Twitter icon</title><path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z"/></svg></a>
   <a href="https://github.com/breck7/breckyunits.com"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub icon</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
</div>
</div>
 <h1 class="scrollChrome scrollTitle">
  <a href="./">Breck Yunits' Scroll</a>
</h1>
 <div class="scrollChrome scrollDescription">Some writing about probability, programming, economics and life.</div>
 <div class="scrollPage scrollSingleArticle">
  <div class="scrollArticleCell"><h1><a href="building-a-treebase-with-6.5-million-files.html">Building a TreeBase with 6.5 million files</a></h1>
<div class="scrollArticleDate">January 29, 2020 â€” </div>



<p>In this long post I'm going to do a stupid thing and see what happens. Specifically I'm going to create 6.5 million files in a single folder and try to use Git and Sublime and other tools with that folder. All to explore this new thing I'm working on.</p>

<p><a href="https://treebase.treenotation.org/">TreeBase</a> is a new system I am working on for long-term, strongly-typed collaborative knowledge bases. The design of TreeBase is dumb. It's just a folder with a bunch of files encoded with <a href="https://treenotation.org/">Tree Notation</a>. A row in a normal SQL table in TreeBase is roughly equivalent to a file. The filenames serve as IDs. Instead of each using an optimized binary storage format it just uses plain text like UTF-8. Field names are stored alongside the values in every file. Instead of starting with a schema you can just start adding files and evolve your schema and types as you go.</p>

<p>For example, in this tiny demo <a href="https://github.com/treenotation/jtree/blob/master/treeBase/planets">TreeBase of the planets</a> the file <code>mars.planet</code> looks like this:</p>

<div class="scrollArticleCode">
<code> diameter 6794</code>

<code> surfaceGravity 4</code>

<code> yearsToOrbitSun 1.881</code>

<code> moons 2</code>

</div>

<p>TreeBase is composed of 3 key ingredients.</p>

<p><strong>Ingredient 1: A folder</strong> All that TreeBase requires is a file system (although in theory you could build an analog TreeBase on paper). This means that you can use any tools on your system for editing files for editing your database.</p>

<p><strong>Ingredient 2: Git</strong> Instead of having code to implement any sort of versioning or metadata tracking, you just use Git. Edit your files and use Git for history, branching, collaboration, etc. Because Tree Notation is a line and word based syntax it meshes really well with Git workflows.</p>

<p><strong>Ingredient 3: Tree Notation</strong> The Third Ingredient for making a TreeBase is Tree Notation. Both schemas and data use <a href="https://treenotation.org/">Tree Notation</a>. This is a new very simple syntax for encoding strongly typed data. It's simple, extensible, and plays well with Git.</p>

<h3>TreeBase Compared to Other Database Systems</h3>

<p>Probably hundreds of billions of dollars has gone into designing robust database systems like <a href="https://www.microsoft.com/en-us/sql-server/default.aspx">SQL Server</a>, <a href="https://en.wikipedia.org/wiki/Oracle_Database">Oracle</a>, <a href="https://www.postgresql.org/">PostgreSQL</a>, <a href="https://www.mysql.com/">MySQL</a>, <a href="https://www.mongodb.com/">MongoDB</a>, <a href="https://www.sqlite.org/index.html">SQLite</a>, and so forth. These things run the world. They are incredibly robust and battle-hardened. Everything that can happen is thought of and planned for, and everything that can go wrong has gone wrong (and learned from). These databases can handle trillions of rows, can conduct complex real-time transactions, and survive disasters of all sort. They use sophisticated binary formats and are tuned for specific file systems. Thousands of people have gotten their PhD's working on database technology.</p>

<p>TreeBase doesn't have any of that. TreeBase is stupid. It's just a bunch of files in a folder.</p>

<p>You might be asking yourself "Why use TreeBase at all when great databases exist?". To further put the stupidity of the current TreeBase design into perspective, the <a href="https://devblogs.microsoft.com/bharry/the-largest-git-repo-on-the-planet/">Largest Git Repo on the Planet is Windows</a> which has 3.5 million files. I'm going to try and create a repo with 6.5 million files on my laptop.</p>

<p>Even if you think TreeBase is silly aren't you curious what happens when I try to put 6.5 million files into one folder? I kind of am. If you want an explanation of <em>why</em> TreeBase, I'll get to that near the end of this post.</p>

<p>But first...</p>

<h3>Let's Break TreeBase</h3>

<p>Here again is <a href="https://github.com/treenotation/jtree/tree/master/treeBase/planets">a demo TreeBase</a> with only 8 files.</p>

<p>The biggest TreeBase I work with has on the order of 10,000 files. Some files have thousands of lines, some just a handful.</p>

<p>While TreeBase has been great at this small scale, a question I've been asked, and have wondered myself, is what happens when a TreeBase gets too big?</p>

<p>I'm about to find out, and I'll document the whole thing.</p>

<p>Every time something bad happens I'll include a ðŸ’£.</p>

<h3>Choosing a Topic</h3>

<p>TreeBase is meant for knowledge bases. So all TreeBases center around a topic.</p>

<p>To test TreeBase on a big scale I want something realistic. I wanted to choose some big structured database that thousands of people have contributed to that's been around for a while and see what it would look like as a TreeBase.</p>

<p>IMDB is just such a database and amazingly makes a lot of their data available for <a href="https://www.imdb.com/interfaces/">download</a>. So movies will be the topic and the IMDB dataset will be my test case. </p>

<h3>The Dataset</h3>

<p>First I grabbed the data. I downloaded the 7 files from IMDB to my laptop. After unzipping, they were about 7GB.</p>

<p>One file, the 500MB <code>title.basics.tsv</code>, contained basic data for all the movie and shows in the database.</p>

<p>Here's what that file looks like with <code>head -5 title.basics.tsv</code>:</p>

<div class="scrollArticleCode">
<code> tconst  titleType primaryTitle  originalTitle isAdult startYear endYear runtimeMinutes  genres</code>

<code> tt0000001 short Carmencita  Carmencita  0 1894  \N  1 Documentary,Short</code>

<code> tt0000002 short Le clown et ses chiens  Le clown et ses chiens  0 1892  \N  5 Animation,Short</code>

<code> tt0000003 short Pauvre Pierrot  Pauvre Pierrot  0 1892  \N  4 Animation,Comedy,Romance</code>

<code> tt0000004 short Un bon bock Un bon bock 0 1892  \N  \N  Animation,Short</code>

</div>

<p>This looks like a good candidate for TreeBase. With this TSV I can create a file for each movie. I don't need the other 6 files for this experiment, though if this was a real project I'd like to merge in that data as well (in that case I'd probably create a second TreeBase for the <code>names</code> in the IMDB dataset).</p>

<p>Doing a simple line count <code>wc -l title.basics.tsv</code> I learn that there are around 6.5M titles in <code>title.basics.tsv</code>. With the current implementation of TreeBase this would be 6.5M files in 1 folder. That should handily break things.</p>

<p>The TreeBase design calls for me to create 1 file for every row in that TSV file. To again stress how dumb this design is keep in mind a 500MB TSV with 6.5M rows can be parsed and analyzed with tools like R or Python in seconds. You could even load the thing near instantly into a SQLite database and utilize any SQL tool to explore the dataset. Instead I am about to spend hours, perhaps days, turning it into a TreeBase.</p>

<h3>From 1 File to 6.5 Million Files</h3>

<p>What will happen when I split 1 file into 6.5 million files? Well, it's clear I am going to waste some space.</p>

<p>A file doesn't just take up space for its contents: it also has metadata. Every file contains metadata like permissions, modification time, etc. That metadata must take up some space, right? If I were to create 6.5M new files, how much extra space would that take up?</p>

<p>My MacBook uses <a href="https://en.wikipedia.org/wiki/Apple_File_System">APFS</a>. It can hold up to 9,000,000,000,000,000,000 files. I can't easily find hard numbers on how much metadata one file takes up but can at least start with a ballpark estimate.</p>

<p>I'll start by considering the space filenames will take up.</p>

<p>In TreeBase filenames are composed of a permalink and a file extension. The file extension is to make it easier for editors to understand the schema of a file. In the planets TreeBase above, the files all had the <code>planet</code> extension and there is a <code>planet.grammar</code> file that contains information for the tools like syntax highlighters and type checkers. For my new IMDB TreeBase there will be a similar <code>title.grammar</code> file and each file will have the ".title" extension. So that is 6 bytes per file. Or merely 36MB extra for the file extensions.</p>

<p>Next, the body of each filename will be a readable ID. TreeBase has meaningful filenames to work well with Git and existing file tools. It keeps things simple. For this TreeBase, I will make the ID from the primaryTitle column in the dataset. Let's see how much space that will take.</p>

<p>I'll try <code>xsv select primaryTitle title.basics.tsv | wc</code>.</p>

<p>ðŸ’£ I got this error:</p>

<div class="scrollArticleCode">
<code> CSV error: record 1102213 (line: 1102214, byte: 91470022): found record with 8 fields, but the previous record has 9 fields</code>
<code>  1102213 3564906 21815916</code>

</div>

<p><a href="https://github.com/BurntSushi/xsv">XSV</a> didn't like something in that file. Instead of getting bogged down, I'll just work around it.</p>

<p>I'll build a subset from the first 1M rows with <code>head -n 1000000 title.basics.tsv > 1m.title.basics.tsv</code>. Now I will compute against that subset with <code>xsv select primaryTitle 1m.title.basics.tsv | wc</code>. I get <code>19751733</code> so an average of 20 characters per title.</p>

<p>I'll combine that with the space for file extension and round that to say 30 extra bytes of file information for each of the 6.5 million titles. <strong>So about 200MB of extra data required to split this 500MB file into filenames. Even though that's a 50% increase, 200MB is dirt cheap so that doesn't seem so bad.</strong></p>

<p>You may think that I could save a roughly equivalent amount by dropping the primaryTitle field. However, even though my filenames now contain information from the title, my permalink schema will generally distort the title so I need to preserve it in each file and won't get savings there. I use a more restrictive character set in the permalink schema than the file contents just to make things like URLs easier.</p>

<p>Again you might ask why not just an integer for the permalink? You could but that's not the TreeBase way. The human readable permalinks play nice with tools like text editors, URLs, and Git. TreeBase is about leveraging software that already works well with file systems. If you use meaningless IDs for filenames you do away with one of the very useful features of the TreeBase system.</p>

<p>But I won't just waste space in metadata. I'm also going to add duplicate data to the contents of each file. That's because I won't be storing just values like <code>1999</code> but I'll also be repeating column names in each file like <code>startYear 1999</code>.</p>

<p>How much space will this take up? The titles file has 9 columns and using <code>head -n 1 1m.title.basics.tsv | wc</code> I see that adds up to 92 bytes. I'll round that up to 100, and multiple by 6.5M, and that adds up to about 65,000,000 duplicate words and 650MB. In other words the space requirements roughly doubled (of course, assuming no compression by the file system under the hood).</p>

<p>You might be wondering why not just drop the column names from each file? Again, it's just not the TreeBase way. By including the column names, each file is self-documenting. I can open up any file with a text editor and easily change it.</p>

<p><strong>So to recap: splitting this 1 TSV file into 6.5 million files is going to take up 2-3x more space due to metadata and repetition of column names.</strong></p>

<p>Because this is text data, that's actually not so bad. I don't foresee problems arising from wasted disk space.</p>

<h3>Foreseeing Speed Problems</h3>

<p>Before I get to the fun part, I'm going to stop for a second and try and predict what the problems are going to be.</p>

<p>Again, in this experiment I'm going to build and attempt to work with a TreeBase roughly 1,000 times larger than any I've worked with before. A 3 order of magnitude jump.</p>

<p>Disk space won't be a problem. But are the software tools I work with on a day-to-day basis designed to handle millions of files in a single folder? How will they hold up?</p>

<ul>
 <li><strong>Bash</strong> How will the basics like <code>ls</code> and <code>grep</code> hold up in a folder with 6.5M files?</li>
 <li><strong>Git</strong> How slow will <code>git status</code> be? What about <code>git add</code> and <code>git commit</code>?</li>
 <li><strong>Sublime Text</strong> Will I even be able to open this folder in Sublime Text? Find/replace is something I so commonly use, will that work?  How about regex find/replace?</li>
 <li><strong>Finder</strong> Will I be able to visually browse around?</li>
 <li><strong>TreeBase Scripts</strong> Will my simple TreeBase scripts be usable? Will I be able to type check a TreeBase?</li>
 <li><strong>GitHub</strong> Will GitHub be able to handle 6.5M files?</li>
</ul>

<h3>Proceeding in Stages</h3>

<p>Since I am going to make a 3 order of magnitude jump, I figured it would be best to make those jumps one at a time.</p>

<p>Actually, to be smart, I will create 5 TreeBases and make 4 jumps. I'll make 1 small TreeBase for sanity checks and then four where I increase by 10x 3 times and see how things hold up.</p>

<p>First, I'll create 5 folders: <code>mkdir 60; mkdir 6k; mkdir 60k; mkdir 600k; mkdir 6m</code></p>

<p>Now I'll create 4 smaller subsets for the smaller bases. For the final 6.5M base I'll just use the original file.</p>

<div class="scrollArticleCode">
<code> head -n 60 title.basics.tsv > 60/titles.tsv</code>

<code> head -n 6000 title.basics.tsv > 6k/titles.tsv</code>

<code> head -n 60000 title.basics.tsv > 60k/titles.tsv</code>

<code> head -n 600000 title.basics.tsv > 600k/titles.tsv</code>

</div>

<p>Now I'll write a script to turn those TSV rows into TreeBase files.</p>

<div class="scrollArticleCode">
<code> #! /usr/local/bin/node --use_strict</code>

<code> const { jtree } = require("jtree")</code>

<code> const { Disk } = require("jtree/products/Disk.node.js")</code>

<code> const folder = "600k"</code>

<code> const path = <code>${__dirname}/../imdb/${folder}.titles.tsv</code></code>

<code> const tree = jtree.TreeNode.fromTsv(Disk.read(path).trim())</code>

<code> const permalinkSet = new Set()</code>

<code> tree.forEach(node => {</code>
<code>   let permalink = jtree.Utils.stringToPermalink(node.get("primaryTitle"))</code>
<code>   let counter = ""</code>
<code>   let dash = ""</code>
<code>   while (permalinkSet.has(permalink + dash + counter)) {</code>
<code>     dash = "-"</code>
<code>     counter = counter ? counter + 1 : 2</code>
<code>   }</code>
<code>   const finalPermalink = permalink + dash + counter</code>
<code>   permalinkSet.add(finalPermalink)</code>
<code>   // Delete Null values:</code>
<code>   node.forEach(field => {</code>
<code>     if (field.getContent() === "\\N") field.destroy()</code>
<code>   })</code>
<code>   if (node.get("originalTitle") === node.get("primaryTitle")) node.getNode("originalTitle").destroy()</code>
<code>   Disk.write(<code>${__dirname}/../imdb/${folder}/${finalPermalink}.title</code>, node.childrenToString())</code>

<code> })</code>

</div>

<p>The script iterates over each node and creates a file for each row in the TSV.</p>

<p>This script required a few design decisions. For permalink uniqueness, I simply keep a set of titles and number them if a name comes up multiple times. There's also the question of what to do with nulls. IMDB sets the value to <code>\N</code>. Generally the TreeBase way is to not include the field in question. So I filtered out null values. For cases where <code>primaryTitle === originalTitle</code>, I stripped the latter. For the Genres field, it's a CSV array. I'd like to make that follow the TreeBase convention of a SSV. I don't know all the possibilities though without iterating, so I'll just skip this for now.</p>

<p>Here are the results of the script for the small 60 file TreeBase:</p>

<p><img src="60files.png" /></p>

<h3>Building the Grammar File</h3>

<p>The Grammar file adds some intelligence to a TreeBase. You can think of it as the schema for your base. TreeBase scripts can read those Grammar files and then do things like provide type checking or syntax highlighting.</p>

<p>Now that we have a sample <code>title</code> file, I'm going to take a first pass at the grammar file for our TreeBase. I copied the file <code>the-photographical-congress-arrives-in-lyon.title</code> and pasted it into the right side of the <a href="https://jtree.treenotation.org/designer/">Tree Language Designer</a>. Then I clicked <code>Infer Prefix Grammar</code>.</p>

<p>That gave me a decent starting point for the grammar:</p>

<div class="scrollArticleCode">
<code> inferredLanguageNode</code>
<code>  root</code>
<code>  inScope tconstNode titleTypeNode primaryTitleNode originalTitleNode isAdultNode startYearNode runtimeMinutesNode genresNode</code>

<code> keywordCell</code>

<code> anyCell</code>

<code> bitCell</code>

<code> intCell</code>

<code> tconstNode</code>
<code>  crux tconst</code>
<code>  cells keywordCell anyCell</code>

<code> titleTypeNode</code>
<code>  crux titleType</code>
<code>  cells keywordCell anyCell</code>

<code> primaryTitleNode</code>
<code>  crux primaryTitle</code>
<code>  cells keywordCell anyCell anyCell anyCell anyCell anyCell anyCell</code>

<code> originalTitleNode</code>
<code>  crux originalTitle</code>
<code>  cells keywordCell anyCell anyCell anyCell anyCell anyCell anyCell anyCell anyCell</code>

<code> isAdultNode</code>
<code>  crux isAdult</code>
<code>  cells keywordCell bitCell</code>

<code> startYearNode</code>
<code>  crux startYear</code>
<code>  cells keywordCell intCell</code>

<code> runtimeMinutesNode</code>
<code>  crux runtimeMinutes</code>
<code>  cells keywordCell bitCell</code>

<code> genresNode</code>
<code>  crux genres</code>
<code>  cells keywordCell anyCell</code>

</div>

<p>The generated grammar needed a little work. I renamed the root node and added catchAlls and a base "abstractFactType". The Grammar language and tooling for TreeBase is very new, so all that should improve as time goes on.</p>

<p>My <code>title.grammar</code> file now looks like this:</p>

<div class="scrollArticleCode">
<code> titleNode</code>
<code>  root</code>
<code>  pattern \.title$</code>
<code>  inScope abstractFactNode</code>

<code> keywordCell</code>

<code> anyCell</code>

<code> bitCell</code>

<code> intCell</code>

<code> abstractFactNode</code>
<code>  abstract</code>
<code>  cells keywordCell anyCell</code>

<code> tconstNode</code>
<code>  crux tconst</code>
<code>  extends abstractFactNode</code>

<code> titleTypeNode</code>
<code>  crux titleType</code>
<code>  extends abstractFactNode</code>

<code> primaryTitleNode</code>
<code>  crux primaryTitle</code>
<code>  extends abstractFactNode</code>
<code>  catchAllCellType anyCell</code>

<code> originalTitleNode</code>
<code>  crux originalTitle</code>
<code>  extends abstractFactNode</code>
<code>  catchAllCellType anyCell</code>

<code> isAdultNode</code>
<code>  crux isAdult</code>
<code>  cells keywordCell bitCell</code>
<code>  extends abstractFactNode</code>

<code> startYearNode</code>
<code>  crux startYear</code>
<code>  cells keywordCell intCell</code>
<code>  extends abstractFactNode</code>

<code> runtimeMinutesNode</code>
<code>  crux runtimeMinutes</code>
<code>  cells keywordCell intCell</code>
<code>  extends abstractFactNode</code>

<code> genresNode</code>
<code>  crux genres</code>
<code>  cells keywordCell anyCell</code>
<code>  extends abstractFactNode</code>

</div>

<p>Next I coped that file into the <code>60</code> folder with <code>cp /Users/breck/imdb/title.grammar 60/</code>. I have the <code>jtree</code> package installed on my local machine so I registered this new language with that with the command <code>jtree register /Users/breck/imdb/title.grammar</code>. Finally, I generated a Sublime syntax file for these title files with <code>jtree sublime title #pathToMySublimePluginDir</code>.</p>

<p>Now I have rudimentary syntax highlighting for these new title files:</p>

<p><img src="sublimeText.png" /></p>

<p>Notice the syntax highlighting is a little broken. The Sublime syntax generating still <a href="https://github.com/treenotation/jtree/issues/8">needs some work</a>.</p>

<p>Anyway, now we've got the basics done. We have a script for turning our CSV rows into Tree Notation files and we have a basic schema/grammar for our new TreeBase.</p>

<p>Let's get started with the bigger tests now.</p>

<h3>A 6k TreeBase</h3>

<p>I'm expecting this to be an easy one. I update my script to target the 6k files and run it with <code>/Users/breck/imdb/build.js</code>. A little alarmingly, it takes a couple of seconds to run:</p>

<div class="scrollArticleCode">
<code> real  0m3.144s</code>

<code> user  0m1.203s</code>

<code> sys 0m1.646s</code>

</div>

<p>The main script is going to iterate over 1,000x as many items so if this rate holds up it would take 50 minutes to generate the 6M TreeBase!</p>

<p>I do have some optimization ideas in mind, but for now let's explore the results.</p>

<p>First, let me build a catalog of typical tasks that I do with TreeBase that I will try to repeat with the 6k, 60k, 600k, and 6.5M TreeBases.</p>

<p>I'll just list them in Tree Notation:</p>

<div class="scrollArticleCode">
<code> task ls</code>
<code>  category bash</code>
<code>  description</code>

<code> task open sublime</code>
<code>  category sublime</code>
<code>  description Start sublime in the TreeBase folder</code>

<code> task sublime responsiveness</code>
<code>  category sublime</code>
<code>  description scroll and click around files in the treebase folder and see how responsive it feels.</code>

<code> task sublime search</code>
<code>  category sublime</code>
<code>  description find all movies with the query "titleType movie"</code>

<code> task sublime regex search</code>
<code>  category sublime</code>
<code>  description find all comedy movies with the regex query "genres ._Comedy._"</code>

<code> task open finder</code>
<code>  category finder</code>
<code>  description open the folder in finder and browse around</code>

<code> task git init</code>
<code>  category git</code>
<code>  description init git for the treebase</code>

<code> task git first status</code>
<code>  category git</code>
<code>  description see git status</code>

<code> task git first add</code>
<code>  category git</code>
<code>  description first git add for the treebase</code>

<code> task git first commit</code>
<code>  category git</code>
<code>  description first git commit</code>

<code> task sublime editing</code>
<code>  category sublime</code>
<code>  description edit some file</code>

<code> task git status</code>
<code>  category git</code>
<code>  description git status when there is a change</code>

<code> task git add</code>
<code>  category git</code>
<code>  description add the change above</code>

<code> task git commit</code>
<code>  category git</code>
<code>  description commit the change</code>

<code> task github push</code>
<code>  category github</code>
<code>  description push the treebase to github</code>

<code> task treebase start</code>
<code>  category treebase</code>
<code>  description how long will it take to start treebase</code>

<code> task treebase error check</code>
<code>  category treebase</code>
<code>  description how long will it take to scan the base for errors.</code>

</div>

<p>ðŸ’£ Before I get to the results, let me note I had 2 bugs. First I needed to update my <code>title.grammar</code> file by adding a <code>cells fileNameCell</code> to the root node and also adding a <code>fileNameCell</code> line. Second, my strategy above of putting the CSV file for each TreeBase into the same folder as the TreeBase was not ideal as Sublime Text would open that file as well. So I moved each file up with <code>mv titles.tsv ../6k.titles.tsv</code>.</p>

<p>The results for 6k are below.</p>

<div class="scrollArticleCode">
<code> category,description,result</code>

<code> bash,ls,instant</code>

<code> sublime,Start sublime in the TreeBase folder,instant</code>

<code> sublime,scroll and click around files in the treebase folder and see how responsive it feels.,nearInstant</code>

<code> sublime,find all movies with the query "titleType movie",neaerInstant</code>

<code> sublime,find all comedy movies with the regex query "genres ._Comedy._",nearInstant</code>

<code> finder,open and browse,instant</code>

<code> git,init git for the treebase,instant</code>

<code> git,see git status,instant</code>

<code> git,first git add for the treebase,aFewSeconds</code>

<code> git,first git commit,instant</code>

<code> sublime,edit some file,instant</code>

<code> git,git status when there is a change,instant</code>

<code> git,add the change above,instant</code>

<code> git,commit the change,instant</code>

<code> github,push the treebase to github,~10 seconds</code>

<code> treebase,how long will it take to start treebase,instant</code>

<code> treebase,how long will it take to scan the base for errors.,nearInstant</code>

</div>

<p>So 6k worked without a hitch. Not surprising as this is in the ballpark of where I normally operate with TreeBases.</p>

<p>Now for the first of three 10x jumps.</p>

<h3>A 60k TreeBase</h3>

<p>ðŸ’£ This markdown file that I'm writing was in the parent folder of the 60k directory and Sublime text seemed to be slowing a bit, so I closed Sublime and created a new unrelated folder to hold this writeup separate from the TreeBase folders.</p>

<p>The build script for the 60k TreeBase took 30 seconds or so, as expected. I can optimize for that later.</p>

<p>I now repeat the tasks from above to see how things are holding up.</p>

<div class="scrollArticleCode">
<code> category,description,result</code>

<code> bash,ls,aFewSeconds</code>

<code> sublime,Start sublime in the TreeBase folder,aFewSeconds with Beachball</code>

<code> sublime,scroll and click around files in the treebase folder and see how responsive it feels.,instant</code>

<code> sublime,find all movies with the query "titleType movie",~20 seconds with beachball</code>

<code> sublime,find all comedy movies with the regex query "genres ._Comedy._",~20 seconds with beachball</code>

<code> git,init git for the treebase,instant</code>

<code> finder,open and browse,6 seconds</code>

<code> git,see git status,nearInstant</code>

<code> git,first git add for the treebase,1 minute</code>

<code> git,first git commit,10 seconds</code>

<code> sublime,edit some file,instant</code>

<code> git,git status when there is a change,instant</code>

<code> git,add the change above,instant</code>

<code> git,commit the change,instant</code>

<code> github,push the treebase to github,~10 seconds</code>

<code> treebase,how long will it take to start treebase,~10 seconds</code>

<code> treebase,how long will it take to scan the base for errors.,~5 seconds</code>

</div>

<p>Uh oh. Already I am noticing some scaling delays with a few of these tasks.</p>

<p>ðŸ’£ The first <code>git add</code> took about 1 minute. I used to know the internals of Git well but that was a decade ago and my knowledge is rusty.</p>

<p>I will now look some stuff up. Could Git be creating 1 file for each file in my TreeBase? I found <a href="https://www.monperrus.net/martin/one-million-files-on-git-and-github">this post</a> from someone who created a Git repo with 1.7M files which should turn out to contain useful information. From that post it looks like you can indeed expect 1 file for Git for each file in the project.</p>

<p>The first <code>git commit</code> took about 10 seconds. Why? Git printed a message about <a href="https://stackoverflow.com/questions/8633981/what-does-auto-packing-the-repository-for-optimum-performance-mean/16233094">Autopacking</a>. It seems Git will combine a lot of small files into packs (perhaps in bundles of 6,700, though I haven't dug in to this) to speed things up. Makes sense.</p>

<p>ðŸ’£ I forgot to mention, while doing the tasks for the 60k TreeBase, my computer fan kicked on. A brief look at Activity Monitor showed a number of <code>mdworker_shared</code> processes using single digit CPU percentages each, which appears to be some <a href="https://discussions.apple.com/thread/8510132">OS level indexing process</a>. That's hinting that a bigger TreeBase might require at least some basic OS/file system config'ing.</p>

<p>Besides the delays with <code>git</code> everything else seemed to remain fast. The 60k TreeBase choked a little more than I'd like but seems with a few tweaks things could remain screaming fast.</p>

<p>Let's move on to the first real challenge.</p>

<h3>A 600k TreeBase</h3>

<p>ðŸ’£ The first problem I hit immediately in that my <code>build.js</code> is not efficient. I hit a v8 out of memory error. I could solve this by either 1) streaming the TSV one row at a time or 2) cleaning up the unoptimized jtree library to handle bigger data better. I chose to spend a few minutes and go with option 1).</p>

<p>ðŸ’£ It appears the first build script started writing files to the 600k directory before it failed. I had to <code>rm -rf 600k/</code> and that took a surprisingly long time. Probably a minute or so. Something to keep an eye on.</p>

<p>ðŸ’£  I updated my build script to use streams. Unfortunately the streaming <a href="https://www.npmjs.com/package/csv-parse">csv parser</a> I switched to choked on line 32546. Inspecting that vicinity it was hard to detect what it was breaking on. Before diving in I figured I'd try a <a href="https://www.npmjs.com/package/csv-parser">different library</a>.</p>

<p>ðŸ’£ The new library seemed to be working but it was taking a while so I added some instrumentation to the script. From those logs the new script seems to generate about 1.5k files per second. So should take about 6 minutes for all 600k. For the 6.5M files, that would grow to an hour, so perhaps there's more optimization work to be done here.</p>

<p>ðŸ’£ Unfortunately the script exited early with:</p>

<div class="scrollArticleCode">
<code> Error: ENAMETOOLONG: name too long, open '/Users/breck/imdbPost/../imdb/600k/mord-an-lottomillionr-karl-hinrich-charly-l.sexualdelikt-an-carola-b.bankangestellter-zweimal-vom-selben-bankruber-berfallenmord-an-lottomillionr-karl-hinrich-charly-l.sexualdelikt-an-carola-b.bankangestellter-zweimal-vom-selben-bankruber-berfallen01985nncrimenews.title'</code>

</div>

<p>Turns out the Apple File System has a filename <a href="https://en.wikipedia.org/wiki/Comparison_of_file_systems">size limit</a> of 255 UTF-8 characters so this error is understandable. However, inspecting the filename shows that for some reason the permalink was generated by combining the original title with the primary title. Sounds like a bug.</p>

<p>I <code>cd</code> into the <code>600k</code> directory to see what's going on.</p>

<p>ðŸ’£ Unfortunately <code>ls</code> hangs. <code>ls -f -1 -U</code> seems to go faster.</p>

<p>The titles look correct. I'm not sure why the script got hung up on that one entry. For now I'll just wrap the function call in a Try/Catch and press on. I should probably make this script resumable but will skip that for now.</p>

<p>Rerunning the script...it worked! That line seemed to be the only problematic line.</p>

<p>We now have our 600k TreeBase.</p>

<div class="scrollArticleCode">
<code> category,description,result</code>

<code> bash,ls,~30 seconds</code>

<code> sublime,Start sublime in the TreeBase folder,failed</code>

<code> sublime,scroll and click around files in the treebase folder and see how responsive it feels.,X</code>

<code> sublime,find all movies with the query "titleType movie",X</code>

<code> sublime,find all comedy movies with the regex query "genres ._Comedy._",X</code>

<code> finder,open and browse,3 minutes</code>

<code> git,init git for the treebase,nearInstant</code>

<code> git,see git status,6s</code>

<code> git,first git add for the treebase,40 minutes</code>

<code> git,first git commit,10 minutes</code>

<code> sublime,edit some file,X</code>

<code> git,git status when there is a change,instant</code>

<code> git,add the change above,instant</code>

<code> git,commit the change,instant</code>

<code> github,push the treebase to github,~10 seconds</code>

<code> treebase,how long will it take to start treebase,~10 seconds</code>

<code> treebase,how long will it take to scan the base for errors.,~5 seconds</code>

</div>

<p>ðŸ’£ <code>ls</code> is now nearly unusable. <code>ls -f -1 -U</code> takes about 30 seconds. A straight up <code>ls</code> takes about 45s.</p>

<p>ðŸ’£ Sublime Text failed to open. After 10 minutes of 100% CPU usage and <a href="Spinning_pinwheel">beachball'ing</a> I force quit the program. I tried twice to be sure with the same result.</p>

<p>ðŸ’£ <code>mdworker_shared</code> again kept my laptop running hot. I found a way of potentially <a href="http://osxdaily.com/2011/12/30/exclude-drives-or-folders-from-spotlight-index-mac-os-x/">disabling Mac OS X Spotlight Indexing</a> of the IMDB folder.</p>

<p>ðŸ’£ Opening the <code>600k</code> folder in Apple's Finder gave me a loading screen for about 3 minutes</p>

<p><img src="600k-finder-loading.png"></p>

<p>At least it eventually came up:</p>

<p><img src="600k-finder.png"></p>

<p>Now, how about Git?</p>

<p>ðŸ’£ The first <code>git add .</code> took <em>40 minutes</em>! Yikes.</p>

<div class="scrollArticleCode">
<code> real  39m30.215s</code>

<code> user  1m19.968s</code>

<code> sys 13m49.157s</code>

</div>

<p>ðŸ’£ <code>git status</code> after the initial git add took about a minute.</p>

<p>ðŸ’£ The first <code>git commit</code> after the git add took about 10 minutes.</p>

<p>GitHub turns out to be a real champ. Even with 600k files the first <code>git push</code> took less than 30 seconds.</p>

<div class="scrollArticleCode">
<code> real  0m22.406s</code>

<code> user  0m2.657s</code>

<code> sys 0m1.724s</code>

</div>

<p>The <a href="https://github.com/breck7/600k">600k repo</a> on GitHub comes up near instantly. GitHub just shows the first 1k out of 600k files which I think is a good compromise, and far better than a multiple minute loading screen.</p>

<p>ðŸ’£ Sadly there doesn't seem to be any pagination for this situation on GitHub, so not sure how to view the rest of the directory contents.</p>

<p>I can pull up a file quickly on GitHub, like the entry for <a href="https://github.com/breck7/600k/blob/master/007-licence-to-kill.title">License to Kill</a>.</p>

<p>How about editing files locally? Sublime is no use so I'll use <code>vim</code>. Because <code>ls</code> is so slow, I'll find the file I want to edit on GitHub. Of course because I can't find pagination in GitHub I'll be limited to editing one of the first 1k files. I'll use just that License to Kill entry.</p>

<p>So the command I use <code>vim 007-licence-to-kill.title</code>. Editing that file is simple enough. Though I wish we had support for Tree Notation in vim to get syntax highlighting and such.</p>

<p>ðŸ’£ Now I do <code>git add .</code>. Again this takes a while. What I now realize is that my fancy command prompt does some <code>git status</code> with every command. So let's disable that.</p>

<p>After going in and cleaning up my shell (including switching to zsh) I've got a bit more performance back on the command line.</p>

<p>ðŸ’£ But just a bit. A <code>git status</code> still takes about 23 seconds! Even with the <code>-uno</code> option it takes about 15 seconds. This is with 1 modified file.</p>

<p>Now adding this 1 file seems tricky. Most of the time I do a <code>git status</code> and see that I want to add everything so I do a <code>git add .</code>.</p>

<p>ðŸ’£ But I tried <code>git add .</code> in the 600k TreeBase and after 100 seconds I killed the job. Instead I resorted to <code>git add 007-licence-to-kill.title</code> which worked pretty much instantly.</p>

<p>ðŸ’£ <code>git commit</code> for this 1 change took about 20 seconds. Not too bad but much worse than normal.</p>

<p><code>git push</code> was just a few seconds.</p>

<p>I was able to <a href="https://github.com/breck7/600k/blob/master/007-licence-to-kill.title">see the change on GitHub</a> instantly. Editing that file on GitHub and committing was a breeze. Looking at the change history and blame on GitHub was near instant.</p>

<p>Git blame locally was also just a couple of seconds.</p>

<h4>Pause to Reflect</h4>

<p>So TreeBase struggles at the 600k level. You cannot just use TreeBase at the 100k level without preparing your system for it. Issues arise with GUIs like Finder and Sublime, background file system processes, shells, git, basic bash utilities, and so forth.</p>

<p>I haven't looked yet into RAM based file systems or how to setup my system to make this use case work well, but for now, out of the box, I cannot recommend TreeBase for databases of more than 100,000 entities.</p>

<p>Is there even a point now to try 6.5M? Arguably no.</p>

<p>However, I've come this far! No turning back now.</p>

<h3>A 6.5M TreeBase</h3>

<p>To recap what I am doing here: I am taking a single 6.5 million row 500MB TSV file that could easily be parsed into a SQLite or other battle hardened database and instead turning it into a monstrous 6.5 million file TreeBase backed by Git and writing it to my hard disk with no special configuration.</p>

<p>By the way, I forgot to mention my system specs for the record. I'm doing this on a MacBook Air running macOS Catalina on a 2.2Ghz Dual-core i7 with 8GB of 1600 Mhz DDR3 Ram with a 500GB Apple SSD using APFS. This is the last MacBook with a great keyboard, so I really hope it doesn't break.</p>

<p>Okay, back to the task at hand.</p>

<p>I need to generate the 6.5M files in a single directory. The 600k TreeBase took 6 minutes to generate so if that scales linearly 6.5M should take an hour. The first <code>git add</code> for 600k took 40 minutes, so that for 6.5M could take 6 hours. The first <code>git commit</code> for 600k took 10 minutes, so potentially 1.5 hours for 6.5M. So this little operation might take about 10 hours.</p>

<p>I'll stitch these operations together into a shell script and run it overnight (I'll make sure to check the batteries in my smoke detectors first).</p>

<p>Here's the script to run the whole routine:</p>

<div class="scrollArticleCode">
<code> time node buildStream.js</code>

<code> time cd ~/imdb/6m/</code>

<code> time git add .</code>

<code> time git commit -m "initial commit"</code>

<code> time git push</code>

</div>

<p>Whenever running a long script, it's smart to test it with a smaller dataset first. I successfully tested this script with the 6k file dataset. Everything worked. Everything should be all set for the final test.</p>

<p>(Later the next day...)</p>

<h3>It's Alive!</h3>

<p>It worked!!! I now have a TreeBase with over 6 million files in a single directory. Well, a few things worked, most things did not.</p>

<div class="scrollArticleCode">
<code> category,description,result</code>

<code> bash,ls,X</code>

<code> sublime,Start sublime in the TreeBase folder,X</code>

<code> sublime,scroll and click around files in the treebase folder and see how responsive it feels.,X</code>

<code> sublime,find all movies with the query "titleType movie",X</code>

<code> sublime,find all comedy movies with the regex query "genres ._Comedy._",X</code>

<code> finder,open and browse,X</code>

<code> git,init git for the treebase,nearInstant</code>

<code> git,first git add for the treebase,12 hours</code>

<code> git,first git commit,5 hours</code>

<code> sublime,edit some file,X</code>

<code> git,git status when there is a change,X</code>

<code> git,add the change above,X</code>

<code> git,commit the change,X</code>

<code> github,push the treebase to github,X</code>

<code> treebase,how long will it take to start treebase,X</code>

<code> treebase,how long will it take to scan the base for errors.,X</code>

</div>

<p>ðŸ’£ There was a slight hiccup in my script where somehow v8 again ran out of memory. But only after creating 6,340,000 files, which is good enough for my purposes.</p>

<p>ðŸ’£ But boy was this slow! The creation of the 6M+ files took 3 hours and 20 minutes.</p>

<p>ðŸ’£  The first <code>git add .</code> took a whopping 12 hours!</p>

<p>ðŸ’£ The first <code>git commit</code> took 5 hours!</p>

<p>ðŸ’£ A few times when I checked on the machine it was running hot. Not sure if from CPU or Disk or a combination.</p>

<p>ðŸ’£ I eventually quit <code>git push</code>. It quickly completed <code>Counting objects: 6350437, done.</code> but then nothing happened except lots of CPU usage for hours.</p>

<p>Although most programs failed, I was at least able to successfully create this monstrosity and navigate the folder.</p>

<p>The experiment has completed. I took a perfectly usable 6.5M row TSV file and transformed it into a beast that brings some of the most well-known programs out there to their knees.</p>

<p>ðŸ’£ NOTE: I do not recommend trying this at home. My laptop became lava hot at points. Who knows what wear and tear I added to my hard disk.</p>

<h3>What have I learned?</h3>

<p>So that is the end of the experiment. Can you build a Git-backed TreeBase with 6.5M files in a single folder? Yes. Should you? No. Most of your tools won't work or will be far too slow. There's infrastructure and design work to be done.</p>

<p>I was actually pleasantly surprised by the results of this early test. I was confident it was going to fail but I wasn't sure exactly how it would fail and at what scale. Now I have a better idea of that. TreeBase currently sucks at the 100k level.</p>

<p>I also now know that the hardware for this type of system feels ready and it's just parts of some software systems that need to be adapted to handle folders with lots of files. I think those software improvements across the stack will be made and this dumb thing could indeed scale.</p>

<h3>What's Next?</h3>

<p>Now, my focus at the moment is not on big TreeBases. My focus is on making the experience of working with little TreeBases great. I want to help get things like <a href="https://github.com/treenotation/jtree/issues/2">Language Server Protocol</a> going for TreeBases and a Content Management System backed by TreeBase.</p>

<p>But I now can envision how, once the tiny TreeBase experience is nailed, you should be able to use this for bigger tasks. The infrastructure is there to make it feasible with just a few adjustments. There are some config tweaks that can be made, more in-memory approaches, and some straightforward algorithmic additions to make to a few pieces of software. I also have had some fun conversations where people have suggested good sharding strategies that may prove useful without changing the simplicity of the system.</p>

<p>That being said, it would be fun to do this experiment again but this time try and make it work. Once that's a success, it would be fun to try and scale it another 100x, and try to build a TreeBase for something like the 180M paper <a href="https://www.semanticscholar.org/">Semantic Scholar</a> dataset.</p>

<h3>Why Oh Why TreeBase?</h3>

<p>Okay, you might be wondering what is the point of this system? Specifically, why use the file system and why use Tree Notation?</p>

<h4>1) The File System is Going to Be Here for a Long Long Time</h4>

<p>1) About 30m programmers use approximately 100 to 500 general purpose programming languages. All of these actively used general purpose languages have battle tested APIs for interacting with file systems. They don't all have interfaces to every database program. Any programmer, no matter what language they use, without having to learn a new protocol, language, or package, could write code to interact with a TreeBase using knowledge they already have. Almost every programmer uses Git now as well, so they'd be familiar with how TreeBase change control works.</p>

<p>2) Over one billion more casual users are familiar with using their operating system tools for interacting with Files (like Explorer and Finder). Wouldn't it be cool if they could use tools they already know to interact with structured data?</p>

<p>Wouldn't it be cool if we could combine sophisticated type checking, querying, and analytical capabilities of databases with the simplicity of files? Programmers can easily build GUIs on top of TreeBase that have any and all of the functionality of traditional database-backed programs but have the additional advantage of an extremely well-known access vector to their information.</p>

<p>People have been predicting the death of files but these predictions are wrong. Even Apple recently backtracked and added a Files interface to iOS. Files and folders aren't going anywhere. It's a very simple and useful design pattern that works in the analog and digital realm. Files have been around for <a href="https://en.wikipedia.org/wiki/Papyrus">at least 4,500 years</a> and my guess is will be around for another 5,000 years, if the earth doesn't blow up. Instead of dying, on the contrary file systems will keep getting better and better. </p>

<h4>2) Tree Notation is All You Need to Create Meaningful Semantic Content</h4>

<p>People have recognized the value of semantic, strongly typed content for a long time. Databases have been strongly typed since the beginning of databases. Strongly typed programming languages have dominated the software world since the beginning of software.</p>

<p>People have been attempting to build a system for collaborative semantic content for decades. <a href="https://en.wikipedia.org/wiki/XML">XML</a>, <a href="https://www.w3.org/RDF/">RDF</a>, <a href="https://www.w3.org/TR/owl2-overview/">OWL2</a>, <a href="https://json-ld.org/">JSON-LD</a>, <a href="http://schema.org/">Schema.org</a>â€”these are all great projects. I just think they can be simplified and I think one strong refinement is Tree Notation.</p>

<p>I imagine a world where you can effortlessly pass TreeBases around and combine them in interesting ways. As a kid I used to collect baseball cards. I think it would be cool if you could just as easily pass around "cards" like a "TreeBase of all the World's Medicines" or a "TreeBase of all the world's academic papers" or a "TreeBase of all the world's chemical compounds" and because I know how to work with one TreeBase I could get value out of any of these TreeBases. Unlike books or weakly typed content like Wikipedia, TreeBases are computable. They are like specialized little brains that you can build smart things out of.</p>

<p>So I think this could be pretty cool. As dumb as it is.</p>

<p>I would love to hear your thoughts.</p>

<p>Published 1/29/2020</p>
<p class="scrollArticleSourceLink"><a href="https://github.com/breck7/breckyunits.com/blob/main//building-a-treebase-with-6-point-5-million-files.scroll">Article source</a></p></div>
</div>
 <div class="scrollChrome scrollIcons">
  <a href="mailto:breck7@gmail.com"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>Gmail icon</title><path d="M24 5.457v13.909c0 .904-.732 1.636-1.636 1.636h-3.819V11.73L12 16.64l-6.545-4.91v9.273H1.636A1.636 1.636 0 0 1 0 19.366V5.457c0-2.023 2.309-3.178 3.927-1.964L5.455 4.64 12 9.548l6.545-4.91 1.528-1.145C21.69 2.28 24 3.434 24 5.457z"/></svg></a>
  <a href="https://twitter.com/breckyunits"><svg role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Twitter icon</title><path d="M23.953 4.57a10 10 0 01-2.825.775 4.958 4.958 0 002.163-2.723c-.951.555-2.005.959-3.127 1.184a4.92 4.92 0 00-8.384 4.482C7.69 8.095 4.067 6.13 1.64 3.162a4.822 4.822 0 00-.666 2.475c0 1.71.87 3.213 2.188 4.096a4.904 4.904 0 01-2.228-.616v.06a4.923 4.923 0 003.946 4.827 4.996 4.996 0 01-2.212.085 4.936 4.936 0 004.604 3.417 9.867 9.867 0 01-6.102 2.105c-.39 0-.779-.023-1.17-.067a13.995 13.995 0 007.557 2.209c9.053 0 13.998-7.496 13.998-13.985 0-.21 0-.42-.015-.63A9.935 9.935 0 0024 4.59z"/></svg></a>
  <a href="https://github.com/breck7/breckyunits.com"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub icon</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg></a>
</div>
</body>
